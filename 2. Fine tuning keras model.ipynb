{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Optimization and Fine Tuning Deep Learning Model with Keras\n",
    "\n",
    "## Optimization model is hard\n",
    "- Some update may not improving model meaningfully\n",
    "- Optimizing hundreds of parameters with complex relationship\n",
    "- Learning rate to low or to high\n",
    "- Example : Stochastic gradient descent (SGD)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "## Data Preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "TITANIC_PATH = 'data/titanic_all_numeric.csv'\n",
    "\n",
    "titanic = pd.read_csv(TITANIC_PATH)\n",
    "titanic.head()\n",
    "\n",
    "# import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# new predictors and targets\n",
    "predictors = titanic.drop(columns='survived').astype(np.float32)\n",
    "target = to_categorical(titanic['survived'])\n",
    "\n",
    "# separate data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# predictors, pred_data, target, pred_target = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(891, 10)\n(891, 2)\n"
     ]
    }
   ],
   "source": [
    "# 891 data, 10 features\n",
    "print(predictors.shape)\n",
    "print(target.shape)\n",
    "\n",
    "n_cols = predictors.shape[1] # size of features"
   ]
  },
  {
   "source": [
    "## Creating basic model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library \n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# define get_new_model() function\n",
    "def get_new_model(nodes_1=100, nodes_2=100, input_shape = (n_cols,)):\n",
    "    model = Sequential()\n",
    "    # add first layer\n",
    "    model.add(Dense(nodes_1, activation='relu', input_shape = input_shape))\n",
    "\n",
    "    # add second layer\n",
    "    model.add(Dense(nodes_2, activation='relu'))\n",
    "\n",
    "    # add output layer\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "28/28 [==============================] - 0s 1000us/step - loss: 5721122.5000\n",
      "28/28 [==============================] - 0s 929us/step - loss: 8.7239\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6261\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8420\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# learning rate\n",
    "list_lr = 1/10 ** np.arange(4)\n",
    "\n",
    "# loop over learning rates\n",
    "for lr in list_lr:\n",
    "    model = get_new_model()\n",
    "    optimizer = SGD(lr = lr)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "source": [
    "# Model Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20/20 [==============================] - 0s 13ms/step - loss: 0.7401 - accuracy: 0.6132 - val_loss: 0.6353 - val_accuracy: 0.6903\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145a6a32d90>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# using validation split\n",
    "model = get_new_model()\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "source": [
    "## Using EarlyStopping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2580 - accuracy: 0.6051 - val_loss: 0.9724 - val_accuracy: 0.3843\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7219 - accuracy: 0.6196 - val_loss: 0.7109 - val_accuracy: 0.6567\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.6597 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6629 - val_loss: 0.5091 - val_accuracy: 0.7575\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.7063 - val_loss: 0.5032 - val_accuracy: 0.7575\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6950 - val_loss: 0.4694 - val_accuracy: 0.7687\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7287 - val_loss: 0.5170 - val_accuracy: 0.7687\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7223 - val_loss: 0.4787 - val_accuracy: 0.7910\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145a547cd00>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# using EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = get_new_model()\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# create earlystopping object\n",
    "es = EarlyStopping(patience=2)\n",
    "\n",
    "# fit model\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=30, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}